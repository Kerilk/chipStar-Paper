\section{Related Work}
\label{section:relatedWork}

We divide the related work discussion to the following three areas: A) Software which aim to extend the portability of CUDA and/or HIP applications, and to the essential components in this type of software platforms, which are
B) portability layer APIs that hide the runtime aspects of different systems behind a (usually task-based) abstractions, and, C) internal device-program representations that provides a virtual instruction-set abstraction to cover a set of real instruction-sets, in order to enable portability of the kernel programs to various heterogeneous devices. We overview the most relevant work in these areas in the following subsections.

\subsection{Software for Porting CUDA Programs}
\label{subsec:softwareForPortingCUDA}

\textit{Hipstar} is based on HIPCL~\cite{HIPCL}. It is a result of an almost a complete rewrite of the HIPCL code base and maturing it over approximately three years of continuous collaboration work with multiple partners and HPC users. Various missing essential features have been implemented since the initial prototype was published. This article significantly expands upon the original poster abstract that introduced the early-prototype-stage HIPCL. 

Before \textit{hipstar}, there was also an experimental port of the HIPCL code base to utilize Intel's Level Zero~\cite{l0} low level API directly~\cite{HIPLZ}. Both the OpenCL backend of HIPCL and the Level Zero backend were merged to the same code base which we now call \textit{hipstar}. The direct Level Zero access is used as an additional backend for comparison purposes in this article, with the article's primary focus being on the OpenCL backend. 
%However, at the time of this writing, the recommended path from CUDA/HIP to Level Zero goes through the OpenCL backend and PoCL's~\cite{poclIJPP} Level Zero backend since the OpenCL code path has matured longer and is somewhat more robust.

ROCm is the AMD's official GPU software platform~\cite{ROCm}. It consists of a general purpose programming API called Heterogeneous compute Interface for Portability (HIP)~\cite{hip}, and a set of libraries that support different degrees of compatibility with the CUDA platform. HIP is very close to CUDA, and in fact AMD provides a source-to-source translation tool called HIPify that can automate the porting process. Interestingly, although heavily based on the NVIDIA-driven CUDA, AMD now promotes HIP as the primary C++ programming API for their GPU platforms. Since AMD GPUs have increased their market share and received major design wins in large HPC installations, HIP as such has risen in importance as an application-facing interface.

SYCLomatic~\cite{SYCLomatic} is a tool contributed by Intel Corporation that can be used to convert CUDA sources to the cross-vendor open standard SYCL~\cite{SYCL}. Similar to AMD's HIPify, but in contrast to \hipstar which aims for source-level compatibility, SYCLomatic is a source-to-source conversion tool, which has its good and bad sides. Its most apparent benefit is more political than technical; it encourages the further development of the converted application to proceed using the open SYCL standard instead of the single-vendor dictated CUDA. The main drawback is that in reality many code bases are difficult or impossible to convert to SYCL for good due to legacy, political or technical reasons. Being able to target many platforms from single source code using a \hipstar-style approach has its benefits. In addition, since \hipstar is not a linkage-time solution, but requires recompilation, it coincidentally also enforces the political aspect of pushing the application towards open standard APIs, in this case OpenCL and SPIR-V.

% https://github.com/vosen/ZLUDA
ZLUDA~\cite{zluda} is a proof-of-concept level tool for running unmodified CUDA applications on top of \lz by implementing the \cuda driver API in \lz, and converting NVIDIA PTX~\cite{ptx} to SPIR-V at runtime. As it is a proper ``drop-in solution'' that works at linkage time ZLUDA it can execute unmodified CUDA applications. However, its developed has stalled and it only supports a limited subset of applications and only on the Intel devices supported by the Level Zero API. ZLUDA author claims in their web page that they can achieve performance benefits when running straight on top of the lower level \lz instead of the somewhat higher level OpenCL. Since \hipstar supports both, we were able to measure this difference accurately, and found it to be negligible\pj{to do actually}. Another beneficial aspect pointed out by the author is that PTX has instructions which map directly to the Intel GPU instructions which are not exposed in OpenCL C. Although \hipstar uses the OpenCL runtime for portability, it targets SPIR-V instead of OpenCL C as the device-side programming language, thus this drawback does not appear with it. The potential overhead is first passing through LLVM IR, which might lose beneficial information, but that also is found not to be an issue according to the measurements presented in Section~\ref{TODO} \pj{to do actually}.

MCUDA~\cite{MCUDA} is the oldest tool we found for porting CUDA programs to non-NVIDIA platforms. MCUDA does source-to-source translation of kernels in a fashion that the translated kernels can execute efficiently on CPUs on a single CPU thread while respecting the barrier synchronization. In the case of \hipstar, since it uses OpenCL as a portability layer, we can target also similar vectorized CPU execution through CPU-targeting OpenCL implementations such as the Intel OpenCL CPU driver and PoCL's CPU drivers~\cite{poclIJPP}. Both of them are capable of vectorizing work-items across work-groups, which translates to implicit autovectorization of CUDA/HIP kernels across CUDA threads.

Swan~\cite{Swan} is another early source-to-source tool for CUDA porting.\pj{TODO: check if it's actually an API which has CUDA and CL backends?} It generates OpenCL code from CUDA, providing similar level of portability as \hipstar does. It hasn't been kept updated since its introduction. Another similar tool is CU2CL~\cite{CU2CL} published in the same year, which also is now inactive.  In comparison to \hipstar the main technical differences are that \hipstar utilizes the latest version of the OpenCL standard to support the newer CUDA features, uses SPIR-V as the intermediate language (no need to generate textual OpenCL C with its limitations) and it doesn't suffer from problems related to source-to-translations as \hipstar provides source-level compatibility.

The closest related CUDA porting tool to  \hipstar we could find is CUDA-on-CL~\cite{CUDAonCL}. Like \hipstar, it similarly compiles CUDA programs using Clang/LLVM-based compiler chain to binaries which then execute on OpenCL platforms. The main technical differences in \hipstar are related to our use of modern OpenCL standard features to implement some of the features of CUDA. These include using Coarse Grained SVM to implement offsetting device pointers at the host-side and implementing warp-level primitives such as shuffles using the subgroup features. We also propose new standard extensions where there are remaining gaps, and will work actively to get them standardized. Furthermore, CUDAonCL compiles device kernels to OpenCL C whereas \hipstar uses SPIR-V as the portable binary format, of which supported device list is expanded with open source OpenCL implementations.


\subsection{Runtime APIs for Heterogeneous Platform Portability}
\label{subsec:portabilityAPIs}

\pj{Moved this before the program representations so it's nicer to refer to it.}
... \pj{OpenMP:{~\cite{10.1145/3559009.3569687}}}
... \pj{TODO: SYCL.} 
... \pj{TODO: LevelZero.} 
... \pj{TODO: HSA}
Heterogeneous System Architecture (HSA) 

... \pj{TODO: AMD ROCr}
... \pj{TODO: Vulkan compute}
... \pj{TODO: Unified Runtime by Intel and Codeplay}
... \pj{TODO: What other cross-vendor options are there?}


\subsection{Device Program Representations} 
\label{subsec:deviceProgramRepresentations}

\pj{We can move some of this discussion to the compiler section.}
Heterogeneous platforms suffer from the problem of device-side program description portability. There is a wide range of instruction-set architectures the kernels can target, and when the program is distributed in a binary form, the targets are known only at run time. Thus, to cover the format in which the device programs (kernels) are stored is critical, it should cover as many of the potential targets as possible. Unfortunately, at the time of this writing, there still seem to be no clear winner program representation in this regard and various portable implementations of  application-facing APIs are resorting to very fat binaries which store copies of the device program in multiple (virtual) instruction-set architectures to cover the various targets and offloading runtimes it might encounter at execution time. This is the case with~\cite{10.1145/3559009.3569687}, and used to be the case with hipSYCL (now called OpenSYCL)~\cite{10.1145/3529538.3530005}. 

Recently OpenSYCL started storing kernels in LLVM~\cite{LLVM} Intermediate Representation (IR) instead of multiple different binaries depending on the target. In this scheme, LLVM IR is lowered to various target-dependent formats at runtime when the target is known~\cite{OpenSYCLfatbin}. This approach has benefits in comparison to the abundance of binaries in the another alternative, and works in theory, but it is also known that LLVM IR is not supposed to be a portable program representation as it can embed target-specific intrinsics, has target specific data layout and endianness among other challenges. Furthermore, LLVM IR is not guaranteed to be stable across LLVM versions, which means that the fat binaries should have access to an LLVM version the IR was generated with, which at worst requires to embed the LLVM library along and the required backends to the fat binary.\pj{recheck the paper after it's been published in IWOCL 23: Which LLVM IR target it uses in the stored LLVM bitcode?} In fact, the problems of LLVM IR not being target-independent and not being stable across LLVM versions was attempted to be addressed by earlier Standard Portable Intermediate Representation (SPIR) versions 1.2 and 2.0~\cite{SPIR2}. The first SPIR versions were designed to support OpenCL C language kernels and was based on defined versions of LLVM IR, but they were later obsoleted in favor of the SPIR-V~\cite{SPIRV} format used by \hipstar. The goal for SPIR-V is to provide a robust cross-vendor specified intermediate language which is not affected by LLVM upstream changes and that shares specification effort with the Vulkan API~\cite{Vulkan}.

HSA specification defines an intermediate language called HSAIL and a binary representation called BRIG~\cite{HSAIL}. A key difference of HSAIL in comparison to the SPIR-V format \hipstar uses is that HSAIL had a fixed number of registers and an address space for spills unlike SPIR-V, which has infinite virtual registers due to being based on the Static Single Assignment (SSA)~\cite{SSA} representation. There was also a GCC-based frontend for consuming BRIGs in a target-portable fashion, but after activity on HSA quieted, the BRIG FE was removed from the upstream GCC source code repository in a May 2021 commit. 

As a conclusion, while SPIR-V support from hardware vendors is not very extensive as of this writing, it seems to be still the best option for a cross-platform representation given it's an open standard defined democratically by multiple hardware vendors. In addition, thanks in part to good quality open source tooling support available and useful SPIR-V producers such as \hipstar and DPC++ appearing, the list of supported targets is likely growing in the future.
