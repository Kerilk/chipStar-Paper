\section{Related Work}
\label{section:relatedWork}

The origin of \textit{chipstar} is on the HIPCL~\cite{HIPCL} prototype which first tested the concept of compiling HIP programs to fat binaries relying on OpenCL and SPIR-V. The \chipstar tool described in this article is a result of an almost a complete rewrite of the HIPCL code base and over approximately three years of continuous development work by multiple partners and HPC users. The HIPCL code base was initially forked to a separate code base to utilize the Level Zero~\cite{l0} low level API directly (HIPLZ~\cite{HIPLZ}) after which the OpenCL backend of HIPCL and the Level Zero backend of HIPLZ were merged to the same code base discussed in this article.
A large number of missing essential features have been implemented since the initial prototypes were published. This article thus significantly expands upon the original poster abstract that introduced the early-prototype-stage HIPCL and now presents a much more mature software stack usable for a wider range of real-world workloads.
%The direct Level Zero access is used as an additional backend for comparison purposes in this article, with the primary focus being on the OpenCL backend.

%However, at the time of this writing, the recommended path from CUDA/HIP to Level Zero goes through the OpenCL backend and PoCL's~\cite{poclIJPP} Level Zero backend since the OpenCL code path has matured longer and is somewhat more robust.

When comparing \chipstar to other HIP implementations, obviously the original ROCm, the AMD's official GPU software platform~\cite{ROCm}, is the baseline. ROCm consists of the general purpose programming API compilation and runtime support for HIP, and a set of libraries that support different degrees of compatibility with the CUDA platform. \chipstar is not a new backend in addition to the AMD GPU and NVIDIA GPU backends provided by the AMD's offering, but has an important technical difference: \chipstar aims to offer runtime portability by its open standard based fat binary, removing the need to recompile the input software per target vendor platform, which is the case with ROCm.
%\pj{Brice/Paulius: Can you check that this is (still) true?}

%HIP is very close to CUDA, and in fact AMD provides a source-to-source translation tool called HIPify that can automate the porting process. Interestingly, although heavily based on the NVIDIA-driven CUDA, AMD now promotes HIP as the primary C++ programming API for their GPU platforms. Since AMD GPUs have increased their market share and received major design wins in large HPC installations, HIP as such has risen in importance as an application-facing interface.

SYCLomatic~\cite{SYCLomatic} is a tool contributed by Intel Corporation for converting CUDA sources to the cross-vendor open standard SYCL~\cite{SYCL}. Similar to AMD's HIPify, but in contrast to \chipstar which aims for source-level compatibility, SYCLomatic is a source-to-source conversion tool, which has its good and bad sides. The most apparent implication of relying on source-to-source conversion is more about maintenance aspects than technical ones; it neccessitates the further development of the converted application to proceed using the SYCL API instead or in addition to CUDA. The main drawback is that in reality many code bases are difficult or impossible to convert solely to SYCL without having the CUDA version as a backup due to legacy, risk-management or technical reasons. The main benefit is that SYCL is an open standard, in constrast to CUDA, enabling more fair competition ground between hardware vendors. Thus, being able to target many platforms from a fat binary compiled from the unmodified CUDA/HIP source code base using a \chipstar-style open platform approach can have its benefits. Furthermore, since \chipstar is not a linkage-time or binary translation solution, but requires recompilation, it coincidentally also encourages utilizing and further developing the cross-vendor ecosystem APIs it relies upon. Furthermore, as of this writing SYCLomatic supports only CUDA, not HIP, while HIP has an increasing number of new applications implemented directly using it.

% https://github.com/vosen/ZLUDA
ZLUDA~\cite{ZLUDA} is a tool for running unmodified CUDA binaries on AMD GPUs. It works by reimplementing the \cuda driver API, and converting NVIDIA PTX~\cite{ptx} to the vendor-specific IRs. Since it is a ``drop-in solution'' that works at program loading/linkage time, it can execute unmodified CUDA fat binaries, which is very comfortable to the end users as it doesn't require access to the source code of the application. While we see ZLUDA as an excellent tool, it requires reverse engineering CUDA SDK's binary interfaces and keeping up-to-date with the NVIDIA PTX as it evolves. We believe, in the longer term, especially as more of the missing extensions we describe are adopted by OpenCL implementations, \chipstar can provide a more robust solution. 
%Of course only time will tell how well this turns out to be the case. 
In addition, ZLUDA also doesn't support HIP as an input and now only targets AMD GPUs, whereas a key goal of \chipstar is extensive cross-vendor portability.

%However, its developed has stalled and it only supports a limited subset of applications and only on the Intel devices supported by the Level Zero API. ZLUDA author claims in their web page that they can achieve performance benefits when running straight on top of the lower level \lz instead of the somewhat higher level OpenCL. Since \chipstar supports both, we were able to measure this difference accurately, and found it to be negligible\pj{to do actually}.
%A key benefit of skipping a cross-vendor standardized layer is that PTX has instructions which map directly to the Intel GPU instructions which are not exposed in OpenCL C.
%Although \chipstar uses the OpenCL runtime for portability, it targets SPIR-V instead of OpenCL C as the device-side programming language, thus this drawback does not appear with it. The potential overhead is first passing through LLVM IR, which might lose beneficial information, but that also is found not to be an issue according to the measurements presented in Section~\ref{TODO} \pj{to do actually}.

MCUDA~\cite{MCUDA} is the oldest tool we found for porting CUDA programs to non-NVIDIA platforms. MCUDA does source-to-source translation of kernels in a fashion that the translated kernels can execute efficiently on CPUs on a single CPU thread while respecting the barrier synchronization. In the case of \chipstar, since it uses OpenCL as its portability layer, it can similarly target also vectorized CPU execution through CPU-targeting OpenCL implementations such as the Intel OpenCL CPU driver and PoCL's CPU drivers~\cite{PoCL}. Both of them are capable of vectorizing work-items (CUDA/HIP threads) inside work-groups, which translates to implicit autovectorization of CUDA/HIP kernels across CUDA threads and provide the benefits of CPU execution such as easier kernel debugging.

Swan~\cite{Swan} is another early source-to-source tool for CUDA porting. It generates OpenCL code from CUDA, providing similar level of portability as \chipstar does. Another similar tool, CU2CL~\cite{CU2CL} was published in the same year as \cite{Swan}. Neither Swan nor CU2CL are maintained any longer.  In comparison to \chipstar, the main technical differences to these tools are that \chipstar utilizes the latest version of the OpenCL standard to support the newer CUDA/HIP features, uses SPIR-V as the intermediate language (no need to generate textual OpenCL C with its limitations) and it doesn't suffer from problems related to source-to-source translations as \chipstar provides source-level compatibility.

The closest comparable CUDA porting tool we could find is CUDA-on-CL~\cite{CUDAonCL}. Like \chipstar, it similarly compiles CUDA programs using Clang/LLVM-based compiler chain to binaries which then execute on OpenCL platforms. However, similarly to Swan and CU2L, it compiles device kernels to OpenCL C whereas \chipstar uses SPIR-V as the portable binary format. Other technical differences in \chipstar are related to the use of modern OpenCL standard features to implement some of the features of CUDA. These include using SVM to implement raw pointers and implementing warp-level primitives such as shuffles using the subgroup features. 


